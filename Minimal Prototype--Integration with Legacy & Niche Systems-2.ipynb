{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Integration with Legacy & Niche Systems\n",
    "# Author: Rod Villalobos\n",
    "# Purpose: Show an AI prototype \n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(23)\n",
    "\n",
    "# --- 1) Simulate a LEGACY dataset (weird names/formats/units) ---\n",
    "N = 120\n",
    "dates_raw = []\n",
    "for _ in range(N):\n",
    "    if np.random.rand() < 0.7:\n",
    "        # mm/dd/yyyy\n",
    "        d = pd.Timestamp(\"2024-01-01\") + pd.to_timedelta(np.random.randint(0, 365), unit=\"D\")\n",
    "        dates_raw.append(d.strftime(\"%m/%d/%Y\"))\n",
    "    else:\n",
    "        # yyyy-mm-dd\n",
    "        d = pd.Timestamp(\"2024-01-01\") + pd.to_timedelta(np.random.randint(0, 365), unit=\"D\")\n",
    "        dates_raw.append(d.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "legacy_df = pd.DataFrame({\n",
    "    \"PID\": np.arange(1, N + 1),\n",
    "    \"AGE_YRS\": np.random.choice(list(range(18, 90)) + [999, -4], size=N),\n",
    "    \"SEX_CD\": np.random.choice([\"M\", \"F\", \"U\", \"?\"], size=N, p=[0.46, 0.46, 0.04, 0.04]),\n",
    "    \"ENROLL_DT\": dates_raw,\n",
    "    \"HT_IN\": np.random.normal(67, 3.5, size=N),      # inches\n",
    "    \"WT_LB\": np.random.normal(165, 30, size=N),      # pounds\n",
    "    \"SITE\": np.random.choice([\"LA1\", \"NY2\", \"TX3\", \"??\"], size=N, p=[0.4, 0.35, 0.2, 0.05]),\n",
    "})\n",
    "# Inject legacy quirks\n",
    "legacy_df.loc[np.random.choice(N, 4, replace=False), \"HT_IN\"] = np.nan\n",
    "legacy_df.loc[np.random.choice(N, 3, replace=False), \"WT_LB\"] = np.nan\n",
    "legacy_df[\"UNEXPECTED_LEGACY_FLAG\"] = np.random.choice([0, 1], size=N, p=[0.9, 0.1])\n",
    "\n",
    "# --- 2) Define target MODERN schema + mappings ---\n",
    "target_columns = [\"patient_id\", \"age\", \"sex\", \"date_enrolled\", \"height_cm\", \"weight_kg\", \"site_code\"]\n",
    "\n",
    "column_map = {\n",
    "    \"PID\": \"patient_id\",\n",
    "    \"AGE_YRS\": \"age\",\n",
    "    \"SEX_CD\": \"sex\",\n",
    "    \"ENROLL_DT\": \"date_enrolled\",\n",
    "    \"HT_IN\": \"height_cm\",     # will convert inches -> cm\n",
    "    \"WT_LB\": \"weight_kg\",     # will convert pounds -> kg\n",
    "    \"SITE\": \"site_code\",\n",
    "}\n",
    "\n",
    "# Site normalization (legacy codes to canonical)\n",
    "site_map = {\"LA1\": \"LAX\", \"NY2\": \"JFK\", \"TX3\": \"DFW\"}\n",
    "# Sex normalization (legacy)\n",
    "sex_norm = {\"M\": \"M\", \"F\": \"F\", \"U\": None, \"?\": None}\n",
    "\n",
    "# --- 3) Transform legacy -> modern ---\n",
    "# 3a) Basic column renaming (only those in the map)\n",
    "mapped = legacy_df[[c for c in legacy_df.columns if c in column_map]].rename(columns=column_map)\n",
    "\n",
    "# 3b) Convert units + normalize enums + parse dates\n",
    "def inches_to_cm(x):\n",
    "    return x * 2.54 if pd.notna(x) else np.nan\n",
    "\n",
    "def pounds_to_kg(x):\n",
    "    return x * 0.45359237 if pd.notna(x) else np.nan\n",
    "\n",
    "def parse_mixed_date(s):\n",
    "    # try mm/dd/yyyy then yyyy-mm-dd\n",
    "    try:\n",
    "        return pd.to_datetime(s, format=\"%m/%d/%Y\", errors=\"raise\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.to_datetime(s, format=\"%Y-%m-%d\", errors=\"raise\")\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "\n",
    "# Keep counters for transform diagnostics\n",
    "date_failures = 0\n",
    "for i, s in mapped[\"date_enrolled\"].items():\n",
    "    dt = parse_mixed_date(s)\n",
    "    if pd.isna(dt):\n",
    "        date_failures += 1\n",
    "    mapped.at[i, \"date_enrolled\"] = dt\n",
    "\n",
    "mapped[\"height_cm\"] = mapped[\"height_cm\"].apply(inches_to_cm)\n",
    "mapped[\"weight_kg\"] = mapped[\"weight_kg\"].apply(pounds_to_kg)\n",
    "mapped[\"sex\"] = mapped[\"sex\"].map(sex_norm).astype(\"object\")\n",
    "mapped[\"site_code\"] = mapped[\"site_code\"].map(site_map).astype(\"object\")\n",
    "\n",
    "# 3c) Ensure target schema presence + order\n",
    "for col in target_columns:\n",
    "    if col not in mapped.columns:\n",
    "        mapped[col] = np.nan\n",
    "mapped = mapped[target_columns]\n",
    "\n",
    "# --- 4) Mapping coverage + transform diagnostics ---\n",
    "legacy_cols = set(legacy_df.columns)\n",
    "mapped_from_legacy = set(column_map.keys())\n",
    "unmapped_legacy_cols = sorted(list(legacy_cols - mapped_from_legacy))\n",
    "mapping_coverage = round(100.0 * len(mapped_from_legacy) / len(legacy_cols), 1)\n",
    "\n",
    "unit_null_h_cm = int(mapped[\"height_cm\"].isna().sum())\n",
    "unit_null_w_kg = int(mapped[\"weight_kg\"].isna().sum())\n",
    "\n",
    "# --- 5) Validation on MODERN dataset ---\n",
    "ENUMS = {\"sex\": {\"M\", \"F\"}, \"site_code\": {\"LAX\", \"JFK\", \"DFW\"}}\n",
    "RANGES = {\"age\": (18, 90), \"height_cm\": (120.0, 220.0), \"weight_kg\": (35.0, 200.0)}\n",
    "\n",
    "def validate(df: pd.DataFrame) -> dict:\n",
    "    report = {}\n",
    "    report[\"missing_columns\"] = [c for c in target_columns if c not in df.columns]\n",
    "    report[\"unexpected_columns\"] = [c for c in df.columns if c not in target_columns]\n",
    "    report[\"nulls_per_column\"] = {c: int(df[c].isna().sum()) for c in target_columns}\n",
    "    report[\"duplicate_rows_on_patient_id\"] = int(df.duplicated(subset=[\"patient_id\"], keep=False).sum())\n",
    "\n",
    "    enum_viol = {}\n",
    "    for col, allowed in ENUMS.items():\n",
    "        if col in df.columns:\n",
    "            enum_viol[col] = int((df[col].notna() & (~df[col].isin(allowed))).sum())\n",
    "    report[\"enum_violations\"] = enum_viol\n",
    "\n",
    "    range_viol = {}\n",
    "    for col, (low, high) in RANGES.items():\n",
    "        if col in df.columns:\n",
    "            mask = df[col].notna() & ((df[col] < low) | (df[col] > high))\n",
    "            range_viol[col] = int(mask.sum())\n",
    "    report[\"range_violations\"] = range_viol\n",
    "    return report\n",
    "\n",
    "validation = validate(mapped)\n",
    "\n",
    "summary = {\n",
    "    # Mapping / transform\n",
    "    \"mapping_coverage_percent\": mapping_coverage,\n",
    "    \"unmapped_legacy_cols\": len(unmapped_legacy_cols),\n",
    "    \"date_parse_failures\": int(date_failures),\n",
    "    \"height_cm_nulls_after_conv\": unit_null_h_cm,\n",
    "    \"weight_kg_nulls_after_conv\": unit_null_w_kg,\n",
    "    # Validation on modern\n",
    "    \"unexpected_columns_in_modern\": len(validation[\"unexpected_columns\"]),\n",
    "    \"total_nulls_modern\": sum(validation[\"nulls_per_column\"].values()),\n",
    "    \"dup_patient_id_modern\": validation[\"duplicate_rows_on_patient_id\"],\n",
    "    \"enum_violations_total\": sum(validation[\"enum_violations\"].values()),\n",
    "    \"range_violations_total\": sum(validation[\"range_violations\"].values()),\n",
    "}\n",
    "\n",
    "print(\"=== MAPPING / TRANSFORM SUMMARY ===\")\n",
    "print({\n",
    "    \"mapping_coverage_percent\": summary[\"mapping_coverage_percent\"],\n",
    "    \"unmapped_legacy_cols_list\": unmapped_legacy_cols,\n",
    "    \"date_parse_failures\": summary[\"date_parse_failures\"],\n",
    "    \"height_cm_nulls_after_conv\": summary[\"height_cm_nulls_after_conv\"],\n",
    "    \"weight_kg_nulls_after_conv\": summary[\"weight_kg_nulls_after_conv\"],\n",
    "}, \"\\n\")\n",
    "\n",
    "print(\"=== VALIDATION REPORT (MODERN SCHEMA) ===\")\n",
    "print(validation, \"\\n\")\n",
    "\n",
    "print(\"=== SUMMARY (KEY COUNTS) ===\")\n",
    "print(summary, \"\\n\")\n",
    "\n",
    "# --- 6) Quick visualization of key counts ---\n",
    "plot_keys = [\n",
    "    \"unmapped_legacy_cols\",\n",
    "    \"date_parse_failures\",\n",
    "    \"height_cm_nulls_after_conv\",\n",
    "    \"weight_kg_nulls_after_conv\",\n",
    "    \"enum_violations_total\",\n",
    "    \"range_violations_total\",\n",
    "]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(plot_keys, [summary[k] for k in plot_keys])\n",
    "plt.title(\"Integration Issues â€” Mapping & Validation Summary\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
